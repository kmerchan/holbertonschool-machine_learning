# 0x11-attention
This directory contains work with attention mechanism, including transormers and self attention.

## Mandatory Tasks:
0. [RNN Encoder](/supervised_learning/0x11-attention/0-rnn_encoder.py)
1. [Self Attention](/supervised_learning/0x11-attention/1-self_attention.py)
2. [RNN Decoder](/supervised_learning/0x11-attention/2-rnn_decoder.py)
3. [Positional Encoding](/supervised_learning/0x11-attention/4-positional_encoding.py)
4. [Scaled Dot Product Attention](/supervised_learning/0x11-attention/5-sdp_attention.py)
5. [Multi Head Attention](/supervised_learning/0x11-attention/6-multihead_attention.py)
6. [Transformer Encoder Block](/supervised_learning/0x11-attention/7-transformer_encoder_block.py)
7. [Transformer Decoder Block](/supervised_learning/0x11-attention/8-transformer_decoder_block.py)
8. [Transformer Encoder](/supervised_learning/0x11-attention/9-transformer_encoder.py)
9. [Transformer Decoder](/supervised_learning/0x11-attention/10-transformer_decoder.py)
10. [Transformer Network](/supervised_learning/0x11-attention/11-transformer.py)


### test_files directory
The test_files directory contains all files used to test output locally.
